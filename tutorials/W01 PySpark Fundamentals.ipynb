{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988f37e5",
   "metadata": {},
   "source": [
    "# Apache Spark 3.2 (PySpark) Tutorial\n",
    "- Author: Akira Takihara Wang (https://github.com/akiratwang)\n",
    "\n",
    "Tutorial Operating System(s):\n",
    "- Windows 10 and WSL2\n",
    "- Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f39986",
   "metadata": {},
   "source": [
    "# Starting a Spark Session\n",
    "To begin with Spark, we need to start a `SparkSession` class.\n",
    "- `appName`: Name of the Spark app\n",
    "- `config`: Configurations to initialise with. We will initialise this example with `'spark.sql.repl.eagerEval.enabled'` which enables a nicer HTML display (similar to `pandas`) for the DataFrame outputs.\n",
    "    - This is the equivalent of running `spark.conf.set('spark.sql.repl.eagerEval.enabled', True)`\n",
    "    \n",
    "A general note is to understand that Spark is **immutable**. We'll discuss it further down the track, but for now, just remember this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe965a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:15.114443Z",
     "start_time": "2021-11-24T02:52:12.150475Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 13:52:13 WARN Utils: Your hostname, NeonEx resolves to a loopback address: 127.0.1.1; using 10.1.1.247 instead (on interface eth0)\n",
      "21/11/24 13:52:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/24 13:52:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark Fundamentals\") \\\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b90d3b",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "Now that we have a `SparkSession`, we can create `DataFrames` from an existing data source. Here's an example with reading in a sample dataset in CSV format:\n",
    "- `header=True` has been specified as CSVs come with a header row.\n",
    "- `sdf.limit(5)` shows the first 5 rows using the HTML display. The alternative is to use `sdf.show(5)` although it will be displayed using the original Spark UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec3255d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:18.313427Z",
     "start_time": "2021-11-24T02:52:15.116126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>pickup_longitude</th><th>pickup_latitude</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th></tr>\n",
       "<tr><td>2</td><td>1/12/15 0:00</td><td>1/12/15 0:05</td><td>5</td><td>0.96</td><td>-73.97994232</td><td>40.76538086</td><td>1</td><td>N</td><td>-73.96630859</td><td>40.76308823</td><td>1</td><td>5.5</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>7.8</td></tr>\n",
       "<tr><td>2</td><td>1/12/15 0:00</td><td>1/12/15 0:00</td><td>2</td><td>2.69</td><td>-73.97233582</td><td>40.76237869</td><td>1</td><td>N</td><td>-73.99362946</td><td>40.74599838</td><td>1</td><td>21.5</td><td>0.0</td><td>0.5</td><td>3.34</td><td>0.0</td><td>0.3</td><td>25.64</td></tr>\n",
       "<tr><td>2</td><td>1/12/15 0:00</td><td>1/12/15 0:00</td><td>1</td><td>2.62</td><td>-73.96884918</td><td>40.76453018</td><td>1</td><td>N</td><td>-73.97454834</td><td>40.79164124</td><td>1</td><td>17.0</td><td>0.0</td><td>0.5</td><td>3.56</td><td>0.0</td><td>0.3</td><td>21.36</td></tr>\n",
       "<tr><td>1</td><td>1/12/15 0:00</td><td>1/12/15 0:05</td><td>1</td><td>1.2</td><td>-73.99393463</td><td>40.74168396</td><td>1</td><td>N</td><td>-73.99766541</td><td>40.74746704</td><td>1</td><td>6.5</td><td>0.5</td><td>0.5</td><td>0.2</td><td>0.0</td><td>0.3</td><td>8.0</td></tr>\n",
       "<tr><td>1</td><td>1/12/15 0:00</td><td>1/12/15 0:09</td><td>2</td><td>3.0</td><td>-73.98892212</td><td>40.72698975</td><td>1</td><td>N</td><td>-73.97559357</td><td>40.6968689</td><td>2</td><td>11.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>12.3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|pickup_longitude|pickup_latitude|RatecodeID|store_and_fwd_flag|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
       "|       2|        1/12/15 0:00|         1/12/15 0:05|              5|         0.96|    -73.97994232|    40.76538086|         1|                 N|     -73.96630859|     40.76308823|           1|        5.5|  0.5|    0.5|       1.0|         0.0|                  0.3|         7.8|\n",
       "|       2|        1/12/15 0:00|         1/12/15 0:00|              2|         2.69|    -73.97233582|    40.76237869|         1|                 N|     -73.99362946|     40.74599838|           1|       21.5|  0.0|    0.5|      3.34|         0.0|                  0.3|       25.64|\n",
       "|       2|        1/12/15 0:00|         1/12/15 0:00|              1|         2.62|    -73.96884918|    40.76453018|         1|                 N|     -73.97454834|     40.79164124|           1|       17.0|  0.0|    0.5|      3.56|         0.0|                  0.3|       21.36|\n",
       "|       1|        1/12/15 0:00|         1/12/15 0:05|              1|          1.2|    -73.99393463|    40.74168396|         1|                 N|     -73.99766541|     40.74746704|           1|        6.5|  0.5|    0.5|       0.2|         0.0|                  0.3|         8.0|\n",
       "|       1|        1/12/15 0:00|         1/12/15 0:09|              2|          3.0|    -73.98892212|    40.72698975|         1|                 N|     -73.97559357|      40.6968689|           2|       11.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        12.3|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = spark.read.csv('../data/sample.csv', header=True)\n",
    "sdf.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d186f",
   "metadata": {},
   "source": [
    "# Untyped Dataset Operations\n",
    "This is also known as **DataFrame Operations** and is the equivalent to `pandas.DataFrame` methods.\n",
    "\n",
    "Documentation:\n",
    "- PySpark DataFrame APIs: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#dataframe-apis\n",
    "- SparkSQL Functions: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#functions\n",
    "- Available dtypes for schemas: https://spark.apache.org/docs/latest/sql-ref-datatypes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0cc3ae",
   "metadata": {},
   "source": [
    "## Schemas\n",
    "To view the _schema_ in Spark, we can use `.printSchema()` to display it in a tree-like output. It's a more comprehensive equivalent to `df.dtypes` in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc386c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:18.318461Z",
     "start_time": "2021-11-24T02:52:18.314687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- pickup_longitude: string (nullable = true)\n",
      " |-- pickup_latitude: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- dropoff_longitude: string (nullable = true)\n",
      " |-- dropoff_latitude: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f175ee",
   "metadata": {},
   "source": [
    "- As you can see above, all our data types are treated as `string`. As such, it is in your best interest to create a standard **schema** for your datasets.\n",
    "- Creating a schema here is very similar to creating a schema for SQL.\n",
    "\n",
    "We'll be using a DDL string (Data Definition Language) to create a schema.\n",
    "\n",
    "Syntax:\n",
    "```python\n",
    "schema = \"\"\"\n",
    "`COLUMN_NAME_1` DTYPE_,\n",
    "`COLUMN_NAME_2` DTYPE_,\n",
    "...\n",
    "`COLUMN_NAME_N` DTYPE_N\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Note, you need to be careful with `datetimes` as the formats can be inconsistent. You'll need some background context to determine if you can/should use `TIMESTAMP` or if it requires a custom parsing function to fix it.\n",
    "- `DateType` assumes `yyyy-MM-dd`\n",
    "- `TimestampType` assumes `yyyy-MM-dd HH:mm:ss.SSSS`\n",
    "- If it cannot parse the field, it will return `null`\n",
    "\n",
    "If we look at our DataFrame, our `datetime` field is of form `1/12/15 0:00` which follows neither formats. We'll cover the data type conversions in the next notebooks - for now, remember this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf05e4ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:18.322424Z",
     "start_time": "2021-11-24T02:52:18.319998Z"
    }
   },
   "outputs": [],
   "source": [
    "schema = \"\"\"\n",
    "`VendorID` INT,  \n",
    "`tpep_pickup_datetime` STRING, \n",
    "`tpep_dropoff_datetime` STRING,\n",
    "`passenger_count` INT, \n",
    "`trip_distance` DOUBLE, \n",
    "`pickup_longitude` DOUBLE, \n",
    "`pickup_latitude` DOUBLE,\n",
    "`RateCodeID` INT, \n",
    "`store_and_fwd_flag` STRING, \n",
    "`dropoff_longitude` DOUBLE, \n",
    "`dropoff_latitude` DOUBLE,\n",
    "`payment_type` INT, \n",
    "`fare_amount` DOUBLE, \n",
    "`extra` DOUBLE, \n",
    "`mta_tax` DOUBLE, \n",
    "`tip_amount` DOUBLE,\n",
    "`tolls_amount` DOUBLE, \n",
    "`improvement_surcharge` DOUBLE, \n",
    "`total_amount` DOUBLE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644b456",
   "metadata": {},
   "source": [
    "Now that we've created the schema, let's re-read in the CSV with the pre-defined schema. \n",
    "\n",
    "If you want Spark to automatically infer the schema, you can load in your dataset with this argument:\n",
    "- `spark.read.csv(filepath, inferSchema=True, header=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5434d27e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:18.355426Z",
     "start_time": "2021-11-24T02:52:18.323773Z"
    }
   },
   "outputs": [],
   "source": [
    "# del sdf\n",
    "sdf = spark.read.csv('../data/sample.csv', schema=schema, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921b3712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:18.878976Z",
     "start_time": "2021-11-24T02:52:18.356447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>pickup_longitude</th><th>pickup_latitude</th><th>RateCodeID</th><th>store_and_fwd_flag</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th></tr>\n",
       "<tr><td>2</td><td>1/12/15 0:00</td><td>1/12/15 0:05</td><td>5</td><td>0.96</td><td>-73.97994232</td><td>40.76538086</td><td>1</td><td>N</td><td>-73.96630859</td><td>40.76308823</td><td>1</td><td>5.5</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>7.8</td></tr>\n",
       "<tr><td>2</td><td>1/12/15 0:00</td><td>1/12/15 0:00</td><td>2</td><td>2.69</td><td>-73.97233582</td><td>40.76237869</td><td>1</td><td>N</td><td>-73.99362946</td><td>40.74599838</td><td>1</td><td>21.5</td><td>0.0</td><td>0.5</td><td>3.34</td><td>0.0</td><td>0.3</td><td>25.64</td></tr>\n",
       "<tr><td>2</td><td>1/12/15 0:00</td><td>1/12/15 0:00</td><td>1</td><td>2.62</td><td>-73.96884918</td><td>40.76453018</td><td>1</td><td>N</td><td>-73.97454834</td><td>40.79164124</td><td>1</td><td>17.0</td><td>0.0</td><td>0.5</td><td>3.56</td><td>0.0</td><td>0.3</td><td>21.36</td></tr>\n",
       "<tr><td>1</td><td>1/12/15 0:00</td><td>1/12/15 0:05</td><td>1</td><td>1.2</td><td>-73.99393463</td><td>40.74168396</td><td>1</td><td>N</td><td>-73.99766541</td><td>40.74746704</td><td>1</td><td>6.5</td><td>0.5</td><td>0.5</td><td>0.2</td><td>0.0</td><td>0.3</td><td>8.0</td></tr>\n",
       "<tr><td>1</td><td>1/12/15 0:00</td><td>1/12/15 0:09</td><td>2</td><td>3.0</td><td>-73.98892212</td><td>40.72698975</td><td>1</td><td>N</td><td>-73.97559357</td><td>40.6968689</td><td>2</td><td>11.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>12.3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|pickup_longitude|pickup_latitude|RateCodeID|store_and_fwd_flag|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
       "|       2|        1/12/15 0:00|         1/12/15 0:05|              5|         0.96|    -73.97994232|    40.76538086|         1|                 N|     -73.96630859|     40.76308823|           1|        5.5|  0.5|    0.5|       1.0|         0.0|                  0.3|         7.8|\n",
       "|       2|        1/12/15 0:00|         1/12/15 0:00|              2|         2.69|    -73.97233582|    40.76237869|         1|                 N|     -73.99362946|     40.74599838|           1|       21.5|  0.0|    0.5|      3.34|         0.0|                  0.3|       25.64|\n",
       "|       2|        1/12/15 0:00|         1/12/15 0:00|              1|         2.62|    -73.96884918|    40.76453018|         1|                 N|     -73.97454834|     40.79164124|           1|       17.0|  0.0|    0.5|      3.56|         0.0|                  0.3|       21.36|\n",
       "|       1|        1/12/15 0:00|         1/12/15 0:05|              1|          1.2|    -73.99393463|    40.74168396|         1|                 N|     -73.99766541|     40.74746704|           1|        6.5|  0.5|    0.5|       0.2|         0.0|                  0.3|         8.0|\n",
       "|       1|        1/12/15 0:00|         1/12/15 0:09|              2|          3.0|    -73.98892212|    40.72698975|         1|                 N|     -73.97559357|      40.6968689|           2|       11.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        12.3|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad4268",
   "metadata": {},
   "source": [
    "## Basic Operations\n",
    "### Selection\n",
    "To show a specific column, we will use `sdf.select(col).limit(5)`. \n",
    "- The equivalent in `pandas` is `df[col].head()`.\n",
    "\n",
    "To _access_ a specific column, use the `sdf[col]` syntax (equivalent to `df[col]`). Avoid using `sdf.col` or `df.col` as it is **not** robust (cannot handle columns with spaces) or future-proof. \n",
    "\n",
    "For multiple columns, pass them through an array as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "772a482d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:19.138441Z",
     "start_time": "2021-11-24T02:52:18.924303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>passenger_count</th></tr>\n",
       "<tr><td>5</td></tr>\n",
       "<tr><td>2</td></tr>\n",
       "<tr><td>1</td></tr>\n",
       "<tr><td>1</td></tr>\n",
       "<tr><td>2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+\n",
       "|passenger_count|\n",
       "+---------------+\n",
       "|              5|\n",
       "|              2|\n",
       "|              1|\n",
       "|              1|\n",
       "|              2|\n",
       "+---------------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.select('passenger_count').limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ce4837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:19.347929Z",
     "start_time": "2021-11-24T02:52:19.139681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>passenger_count</th><th>trip_distance</th></tr>\n",
       "<tr><td>5</td><td>0.96</td></tr>\n",
       "<tr><td>2</td><td>2.69</td></tr>\n",
       "<tr><td>1</td><td>2.62</td></tr>\n",
       "<tr><td>1</td><td>1.2</td></tr>\n",
       "<tr><td>2</td><td>3.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+-------------+\n",
       "|passenger_count|trip_distance|\n",
       "+---------------+-------------+\n",
       "|              5|         0.96|\n",
       "|              2|         2.69|\n",
       "|              1|         2.62|\n",
       "|              1|          1.2|\n",
       "|              2|          3.0|\n",
       "+---------------+-------------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.select(['passenger_count', 'trip_distance']).limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701cddf",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "For filtering data, we use `sdf.filter(condition).limit(5)`. \n",
    "- The equivalent in `pandas` is `df.loc[condition].head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbff448e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:19.687428Z",
     "start_time": "2021-11-24T02:52:19.349044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>pickup_longitude</th><th>pickup_latitude</th><th>RateCodeID</th><th>store_and_fwd_flag</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th></tr>\n",
       "<tr><td>2</td><td>2015-12-01 00:00:00</td><td>2015-12-01 00:00:00</td><td>5</td><td>0.96</td><td>-73.97994232</td><td>40.76538086</td><td>1</td><td>N</td><td>-73.96630859</td><td>40.76308823</td><td>1</td><td>5.5</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>7.8</td></tr>\n",
       "<tr><td>2</td><td>2015-12-01 00:00:00</td><td>2015-12-01 00:00:00</td><td>5</td><td>0.83</td><td>-74.00122833</td><td>40.75160599</td><td>1</td><td>N</td><td>-73.99243164</td><td>40.75825882</td><td>2</td><td>4.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>5.8</td></tr>\n",
       "<tr><td>2</td><td>2015-12-01 00:00:00</td><td>2015-12-01 00:00:00</td><td>5</td><td>17.7</td><td>-73.7960434</td><td>40.64468002</td><td>2</td><td>N</td><td>-74.00257874</td><td>40.73490906</td><td>1</td><td>52.0</td><td>0.0</td><td>0.5</td><td>11.67</td><td>5.54</td><td>0.3</td><td>70.01</td></tr>\n",
       "<tr><td>2</td><td>2015-12-01 00:00:00</td><td>2015-12-01 00:00:00</td><td>5</td><td>2.57</td><td>-74.01177216</td><td>40.70434952</td><td>1</td><td>N</td><td>-73.98803711</td><td>40.73279953</td><td>1</td><td>11.0</td><td>0.5</td><td>0.5</td><td>1.23</td><td>0.0</td><td>0.3</td><td>13.53</td></tr>\n",
       "<tr><td>2</td><td>2015-12-01 00:00:00</td><td>2015-12-01 00:00:00</td><td>5</td><td>4.1</td><td>-73.97471619</td><td>40.75342178</td><td>1</td><td>N</td><td>-74.00688171</td><td>40.70512009</td><td>1</td><td>14.5</td><td>0.5</td><td>0.5</td><td>3.16</td><td>0.0</td><td>0.3</td><td>18.96</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|pickup_longitude|pickup_latitude|RateCodeID|store_and_fwd_flag|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
       "|       2| 2015-12-01 00:00:00|  2015-12-01 00:00:00|              5|         0.96|    -73.97994232|    40.76538086|         1|                 N|     -73.96630859|     40.76308823|           1|        5.5|  0.5|    0.5|       1.0|         0.0|                  0.3|         7.8|\n",
       "|       2| 2015-12-01 00:00:00|  2015-12-01 00:00:00|              5|         0.83|    -74.00122833|    40.75160599|         1|                 N|     -73.99243164|     40.75825882|           2|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|\n",
       "|       2| 2015-12-01 00:00:00|  2015-12-01 00:00:00|              5|         17.7|     -73.7960434|    40.64468002|         2|                 N|     -74.00257874|     40.73490906|           1|       52.0|  0.0|    0.5|     11.67|        5.54|                  0.3|       70.01|\n",
       "|       2| 2015-12-01 00:00:00|  2015-12-01 00:00:00|              5|         2.57|    -74.01177216|    40.70434952|         1|                 N|     -73.98803711|     40.73279953|           1|       11.0|  0.5|    0.5|      1.23|         0.0|                  0.3|       13.53|\n",
       "|       2| 2015-12-01 00:00:00|  2015-12-01 00:00:00|              5|          4.1|    -73.97471619|    40.75342178|         1|                 N|     -74.00688171|     40.70512009|           1|       14.5|  0.5|    0.5|      3.16|         0.0|                  0.3|       18.96|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.filter(sdf['passenger_count'] == 5).limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90852bd",
   "metadata": {},
   "source": [
    "### GroupBy (Aggregation)\n",
    "To groupby the data (i.e mean), we can use `sdf.groupby(col).mean(aggregated columns).limit(5)`\n",
    "- The equivalent in `pandas` is `df.groupby(col)[aggregated columns].mean().head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c08fa42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:20.603427Z",
     "start_time": "2021-11-24T02:52:19.688463Z"
    }
   },
   "outputs": [],
   "source": [
    "sdf.groupby('passenger_count').mean('trip_distance').limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf6768",
   "metadata": {},
   "source": [
    "We can also apply multiple different aggregations and change their output names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b36e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, median\n",
    "\n",
    "results = sdf.groupBy(\"passenger_count\") \\\n",
    "    .agg(mean(\"total_amount\").alias(\"Average Trip Amount USD$\"),\n",
    "         median(\"trip_distance\").alias(\"Median Trip Distance in Miles\")\n",
    "    ) \n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7abfc",
   "metadata": {},
   "source": [
    "# Spark SQL\n",
    "The `SparkSession` also allows for `SQL` queries to be run with the query results returned as a DataFrame. To do so, we will need to create a temporary SQL view.\n",
    "\n",
    "Temporary SQL Views:\n",
    "- The namespace is session-scoped (not local or global) meaning it will disappear if the `SparkSession` terminates.\n",
    "- If you want a more persistent view that can be shared among all sessions until the Spar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf1f7fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:20.934429Z",
     "start_time": "2021-11-24T02:52:20.604504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>pickup_longitude</th><th>pickup_latitude</th><th>RateCodeID</th><th>store_and_fwd_flag</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th></tr>\n",
       "<tr><td>2</td><td>2015-12-01 00:00:00</td><td>2015-12-01 00:00:00</td><td>5</td><td>0.96</td><td>-73.97994232</td><td>40.76538086</td><td>1</td><td>N</td><td>-73.96630859</td><td>40.76308823</td><td>1</td><td>5.5</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>7.8</td></tr>\n",
       "<tr><td>2</td><td>2015-12-01 00:00:00</td><td>2015-12-01 00:00:00</td><td>5</td><td>0.83</td><td>-74.00122833</td><td>40.75160599</td><td>1</td><td>N</td><td>-73.99243164</td><td>40.75825882</td><td>2</td><td>4.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>5.8</td></tr>\n",
       "<tr><td>2</td><td>2015-12-01 00:00:00</td><td>2015-12-01 00:00:00</td><td>5</td><td>17.7</td><td>-73.7960434</td><td>40.64468002</td><td>2</td><td>N</td><td>-74.00257874</td><td>40.73490906</td><td>1</td><td>52.0</td><td>0.0</td><td>0.5</td><td>11.67</td><td>5.54</td><td>0.3</td><td>70.01</td></tr>\n",
       "<tr><td>2</td><td>2015-12-01 00:00:00</td><td>2015-12-01 00:00:00</td><td>5</td><td>2.57</td><td>-74.01177216</td><td>40.70434952</td><td>1</td><td>N</td><td>-73.98803711</td><td>40.73279953</td><td>1</td><td>11.0</td><td>0.5</td><td>0.5</td><td>1.23</td><td>0.0</td><td>0.3</td><td>13.53</td></tr>\n",
       "<tr><td>2</td><td>2015-12-01 00:00:00</td><td>2015-12-01 00:00:00</td><td>5</td><td>4.1</td><td>-73.97471619</td><td>40.75342178</td><td>1</td><td>N</td><td>-74.00688171</td><td>40.70512009</td><td>1</td><td>14.5</td><td>0.5</td><td>0.5</td><td>3.16</td><td>0.0</td><td>0.3</td><td>18.96</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|pickup_longitude|pickup_latitude|RateCodeID|store_and_fwd_flag|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
       "|       2| 2015-12-01 00:00:00|  2015-12-01 00:00:00|              5|         0.96|    -73.97994232|    40.76538086|         1|                 N|     -73.96630859|     40.76308823|           1|        5.5|  0.5|    0.5|       1.0|         0.0|                  0.3|         7.8|\n",
       "|       2| 2015-12-01 00:00:00|  2015-12-01 00:00:00|              5|         0.83|    -74.00122833|    40.75160599|         1|                 N|     -73.99243164|     40.75825882|           2|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|\n",
       "|       2| 2015-12-01 00:00:00|  2015-12-01 00:00:00|              5|         17.7|     -73.7960434|    40.64468002|         2|                 N|     -74.00257874|     40.73490906|           1|       52.0|  0.0|    0.5|     11.67|        5.54|                  0.3|       70.01|\n",
       "|       2| 2015-12-01 00:00:00|  2015-12-01 00:00:00|              5|         2.57|    -74.01177216|    40.70434952|         1|                 N|     -73.98803711|     40.73279953|           1|       11.0|  0.5|    0.5|      1.23|         0.0|                  0.3|       13.53|\n",
       "|       2| 2015-12-01 00:00:00|  2015-12-01 00:00:00|              5|          4.1|    -73.97471619|    40.75342178|         1|                 N|     -74.00688171|     40.70512009|           1|       14.5|  0.5|    0.5|      3.16|         0.0|                  0.3|       18.96|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a temporary SQL view for the DataFrame\n",
    "sdf.createOrReplaceTempView('taxi')\n",
    "\n",
    "sql_query = spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM taxi\n",
    "WHERE passenger_count == 5\n",
    "    AND trip_distance > 0\n",
    "\"\"\")\n",
    "\n",
    "sql_query.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d607936",
   "metadata": {},
   "source": [
    "# Saving Data\n",
    "By default, Spark will save your data sources as a `parquet` - an open source file format available. It's designed to be efficient and is similar to row based files such as `CSV`. \n",
    "\n",
    "From https://databricks.com/glossary/what-is-parquet:\n",
    "- Parquet is optimized to work with complex data in bulk and features different ways for efficient data compression and encoding types.\n",
    "- This approach is best especially for those queries that need to read certain columns from a large table. \n",
    "- Parquet can only read the needed columns therefore greatly minimizing the IO.\n",
    "\n",
    "In other words, it is both much smaller in size, much faster in query execution, and much _cheaper_ in cost (for cloud-based solutions).\n",
    "\n",
    "As an example, let's save the output of the SQL query we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2ee7c06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:52:21.873893Z",
     "start_time": "2021-11-24T02:52:20.935718Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query.write.save('../data/subset.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4821e861",
   "metadata": {},
   "source": [
    "## Reading in Parquet Files\n",
    "As we had read in a `CSV` above, here's an example of reading in a `parquet` format (the method is quite intuitive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b4a94bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:53:21.990278Z",
     "start_time": "2021-11-24T02:53:21.631781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>pickup_longitude</th><th>pickup_latitude</th><th>RateCodeID</th><th>store_and_fwd_flag</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th></tr>\n",
       "<tr><td>2</td><td>2015-12-04 20:24:00</td><td>2015-12-04 20:24:00</td><td>5</td><td>2.23</td><td>-73.97263336</td><td>40.75886536</td><td>1</td><td>N</td><td>-73.99765015</td><td>40.7432785</td><td>1</td><td>14.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>15.8</td></tr>\n",
       "<tr><td>2</td><td>2015-12-04 20:24:00</td><td>2015-12-04 20:24:00</td><td>5</td><td>13.75</td><td>-73.79033661</td><td>40.64397049</td><td>1</td><td>N</td><td>-73.9159317</td><td>40.62261963</td><td>2</td><td>39.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>40.3</td></tr>\n",
       "<tr><td>2</td><td>2015-12-04 20:24:00</td><td>2015-12-04 20:24:00</td><td>5</td><td>2.24</td><td>-73.98329926</td><td>40.74370956</td><td>1</td><td>N</td><td>-74.00302887</td><td>40.73128128</td><td>1</td><td>14.5</td><td>0.5</td><td>0.5</td><td>3.16</td><td>0.0</td><td>0.3</td><td>18.96</td></tr>\n",
       "<tr><td>2</td><td>2015-12-04 20:24:00</td><td>2015-12-04 20:24:00</td><td>5</td><td>2.36</td><td>-73.96770477</td><td>40.76294708</td><td>1</td><td>N</td><td>-73.94860077</td><td>40.75246429</td><td>2</td><td>10.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>11.3</td></tr>\n",
       "<tr><td>2</td><td>2015-12-04 20:25:00</td><td>2015-12-04 20:25:00</td><td>5</td><td>1.75</td><td>-73.98252869</td><td>40.73942947</td><td>1</td><td>N</td><td>-73.97209167</td><td>40.76068878</td><td>1</td><td>11.5</td><td>0.5</td><td>0.5</td><td>2.56</td><td>0.0</td><td>0.3</td><td>15.36</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|pickup_longitude|pickup_latitude|RateCodeID|store_and_fwd_flag|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
       "|       2| 2015-12-04 20:24:00|  2015-12-04 20:24:00|              5|         2.23|    -73.97263336|    40.75886536|         1|                 N|     -73.99765015|      40.7432785|           1|       14.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        15.8|\n",
       "|       2| 2015-12-04 20:24:00|  2015-12-04 20:24:00|              5|        13.75|    -73.79033661|    40.64397049|         1|                 N|      -73.9159317|     40.62261963|           2|       39.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        40.3|\n",
       "|       2| 2015-12-04 20:24:00|  2015-12-04 20:24:00|              5|         2.24|    -73.98329926|    40.74370956|         1|                 N|     -74.00302887|     40.73128128|           1|       14.5|  0.5|    0.5|      3.16|         0.0|                  0.3|       18.96|\n",
       "|       2| 2015-12-04 20:24:00|  2015-12-04 20:24:00|              5|         2.36|    -73.96770477|    40.76294708|         1|                 N|     -73.94860077|     40.75246429|           2|       10.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        11.3|\n",
       "|       2| 2015-12-04 20:25:00|  2015-12-04 20:25:00|              5|         1.75|    -73.98252869|    40.73942947|         1|                 N|     -73.97209167|     40.76068878|           1|       11.5|  0.5|    0.5|      2.56|         0.0|                  0.3|       15.36|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf2 = spark.read.parquet('../data/subset.parquet')\n",
    "sdf2.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1738b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T02:53:30.376724Z",
     "start_time": "2021-11-24T02:53:30.373866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- RateCodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf2.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
