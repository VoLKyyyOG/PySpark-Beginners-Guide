{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "738ca586",
   "metadata": {},
   "source": [
    "# Working with Larger Datasets with a Scalable Solution!\n",
    "- Consider the full 2015 TLC Taxi Dataset (at ~2GB per month @ ~24GB annually)\n",
    "- Datasets with more than 20k rows would be hard for Excel, but fine for Pandas.\n",
    "- A file with more than 100mil rows (a few GB) is large for Pandas.\n",
    "- Although `pandas` would be sufficient for each month, how about a whole year?\n",
    "\n",
    "That's right, use Spark 3.0!\n",
    "![image.png](https://spark.apache.org/images/spark-logo-trademark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e89012c",
   "metadata": {},
   "source": [
    "## Method 1 (Docker)\n",
    "We will be using:\n",
    "- Docker for Windows 10 with WSL2 Backend (https://www.docker.com/)\n",
    "- AWS Glue container (https://hub.docker.com/r/amazon/aws-glue-libs)\n",
    "\n",
    "Steps:  \n",
    "0. (Pre-Req) Install WSL2.\n",
    "1. Download Docker and install.\n",
    "2. Set WSL2 as backend and restart.\n",
    "3. Launch WSL2 and run `docker pull amazon/aws-glue-libs:glue_libs_1.0.0_image_01`\n",
    "    - tag=`glue_libs_1.0.0_image_01` is the latest as of 2021 July.\n",
    "4. Run and install the container:\n",
    "```bash\n",
    "docker run -itd -p 8888:8888 -p 4040:4040 -v %UserProfile%\\.aws:/root/.aws:rw -v C:\\Users\\YOUR_USERNAME\\Documents\\GitHub:/home/jupyter/jupyter_default_dir --name glue_jupyter amazon/aws-glue-libs:glue_libs_1.0.0_image_01 /home/jupyter/jupyter_start.sh\n",
    "```\n",
    "    - `p` specifies the port\n",
    "    - `-v` specifies the directory for your files\n",
    "    - `--name` specifies the container name (though the container ID will be different)\n",
    "5. Check to see the container is running with `docker ps`\n",
    "6. Launch Jupyter Notebook with your browser and open a `PySpark` kernel.\n",
    "\n",
    "## Method 2 (Preferred)\n",
    "We will be using:\n",
    "- Ubuntu 20.04 (WSL2) or MacOS.\n",
    "\n",
    "Steps:  \n",
    "1. Install WSL2 for Windows 10 users. MacOS users, please ensure your terminal is set to `bash`.\n",
    "2. Setup your Python environment (i.e `pip3 install notebook pandas numpy ...`)\n",
    "3. Install `Java` and `PySpark`:  \n",
    "- Linux\n",
    "```bash\n",
    "# install java\n",
    "sudo apt install openjdk-8-jdk -y\n",
    "# add to path\n",
    "echo 'JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"' | sudo tee -a /etc/environment\n",
    "# apply to environment\n",
    "source /etc/environment\n",
    "# install spark\n",
    "pip3 install pyspark\n",
    "```\n",
    "- MacOS\n",
    "```bash\n",
    "# install java 8 and link to system java wrapper\n",
    "brew install openjdk@8\n",
    "sudo ln -sfn /usr/local/opt/openjdk@8/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk-8.jdk\n",
    "# add to path (earlier OSX defaults to bash while newer ones defaults to zsh)\n",
    "echo 'export JAVA_HOME=\"$(/usr/libexec/java_home -v1.8)\"' | tee -a $HOME/.bashrc $HOME/.zshrc\n",
    "# reload java path\n",
    "source $HOME/.bashrc ; source $HOME/.zshrc\n",
    "# install spark. Note: if you are using anaconda/conda environments, you need to make sure the pip3 is the correct pip3! Or you should install with conda directly!\n",
    "pip3 install pyspark\n",
    "```\n",
    "\n",
    "- MacOS with M1 Chips may need to follow this guide for Java JDK:\n",
    "https://code2care.org/q/install-native-java-jdk-jre-on-apple-silicon-m1-mac\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da69030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T03:52:10.514492Z",
     "start_time": "2021-06-07T03:52:04.660201Z"
    }
   },
   "source": [
    "## Preparation for the Next Part\n",
    "This is a pre-requisite for the next tutorial. To be ready:\n",
    "1. You must already have `PySpark` installed.\n",
    "2. You need the dataset downloaded.\n",
    "\n",
    "The code below downloads all 2015 data directly from the Amazon S3 Bucket. This is approximately ~21.3GB in size, so make sure you have ample storage space. You will only need to run this once.\n",
    "\n",
    "```python\n",
    "from os.path import getsize\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "output_dir = \"../data/large\"\n",
    "fname_template = \"yellow_tripdata_2015\"\n",
    "\n",
    "for m in range(1, 13):\n",
    "    month = str(m).zfill(2)\n",
    "    out = f'{fname_template}-{month}.csv'\n",
    "    url = f\"https://s3.amazonaws.com/nyc-tlc/trip+data/{out}\"\n",
    "    urlretrieve(url, f\"{output_dir}/{out}\")\n",
    "\n",
    "    print(f\"Done downloading {out} to {output_dir} with size {getsize(f'{output_dir}/{out}') / 1073741824:.2f}GB\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a322f164",
   "metadata": {},
   "source": [
    "To verify you've installed it correctly, run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281258d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "sdf = spark.read.csv('../data/sample.csv', header=True)\n",
    "\n",
    "sdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
